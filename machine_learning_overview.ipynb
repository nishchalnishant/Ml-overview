{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning\n",
        "\n",
        "This section covers the fundamentals of Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supervised Learning\n",
        "\n",
        "Supervised learning is a type of machine learning where the model learns from labeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common Supervised Learning Algorithms\n",
        "\n",
        "- **Naive Bayes:** A probabilistic classifier based on Bayes' theorem with an assumption of feature independence.\n",
        "- **Support Vector Machines (SVM):** Finds an optimal hyperplane to separate classes or fit a regression line.\n",
        "- **K-Nearest Neighbors (KNN):** Classifies or predicts based on the majority class or average value of its k closest neighbors.\n",
        "- **Decision Trees:** Tree-like models that make decisions based on feature values.\n",
        "- **Ensemble Learning:** Combines multiple models to improve performance.\n",
        "    - *Random Forest:* An ensemble of decision trees using bagging.\n",
        "    - *Boosting (e.g., AdaBoost, Gradient Boosting):* Sequentially builds models, with each correcting its predecessor's errors.\n",
        "For detailed explanations of these algorithms, see the [Supervised Learning documentation](machine-learning/supervised-learning.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression\n",
        "\n",
        "Regression models predict continuous values.\n",
        "\n",
        "A common algorithm is Linear Regression. Key metrics to evaluate regression models include:\n",
        "- Mean Absolute Error (MAE)\n",
        "- Mean Squared Error (MSE)\n",
        "- Root Mean Squared Error (RMSE)\n",
        "- R-squared\n",
        "For more details, see [Supervised Learning: Regression](machine-learning/supervised-learning.md#regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification\n",
        "\n",
        "Classification models predict discrete categories.\n",
        "\n",
        "A common algorithm is Logistic Regression. Key metrics to evaluate classification models include:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-score\n",
        "- Confusion Matrix\n",
        "For more details, see [Supervised Learning: Classification](machine-learning/supervised-learning.md#classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unsupervised Learning\n",
        "\n",
        "Unsupervised learning is a type of machine learning where the model learns from unlabeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clustering\n",
        "\n",
        "Clustering algorithms group similar data points together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dimensionality Reduction\n",
        "\n",
        "Dimensionality reduction techniques reduce the number of features in a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning\n",
        "\n",
        "This section will cover Deep Learning concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Learning Methods\n",
        "\n",
        "This subsection covers various methods and applications of deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computer Vision\n",
        "\n",
        "# Computer vision\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Natural Language Processing (NLP)\n",
        "\n",
        "# NLP\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generative Models\n",
        "\n",
        "# Generative models\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time Series\n",
        "\n",
        "# Time series\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parts of Deep Learning\n",
        "\n",
        "This subsection covers the fundamental components and concepts of deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activation Functions\n",
        "\n",
        "# Activation functions\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention Mechanisms\n",
        "\n",
        "# Attention\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Autoencoders\n",
        "\n",
        "# Autoencoders\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Backpropagation\n",
        "\n",
        "# Backpropagation\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hidden Layers\n",
        "\n",
        "# Hidden layers\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Functions\n",
        "\n",
        "# Loss Functions\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizers\n",
        "\n",
        "# Optimizers\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regularization\n",
        "\n",
        "# Regularization\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformers\n",
        "\n",
        "# Transformers\n",
        "\n",
        "(Further details to be added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Large Language Models (LLMs)\n",
        "\n",
        "This section will cover Large Language Models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DB Genie\n",
        "\n",
        "Overview\n\n* What is DB Genie\n\nWhat is DB genie ?\n\n* DB defined genie as a compound AI system which is a system that takles AI tasks using multiple interacting components including multiple calls to models, retrievers or external tools.\n* This is in contrast to a AI/ LLm model which is simple a statistical model i.e. a transformer that predicts the next token in the text.\n* Although the models are improving more and more SOTA results are obtained using compound systems. There are several reasons t=for the same\n  * some tasks are easier to improve via LLM design\n    * suppose that the current best LLM can solve coding contest problems 30% of the time, and tripling its training budget would increase this to 35%; this is still not reliable enough to win a coding contest! In contrast, engineering a system that samples from the model multiple times, tests each sample, etc. might increase performance to 80% with today’s models, as shown in work like [AlphaCode](https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf).\n  * Systems can be dynamic\n    * As LLMs are trained on static dataset, thier knowledge is fixed. Thus developers combine models with other components such as search and retrieval to incorporate timely data.\n  * Improving control and trust\n    * Using an Ai system instead of model helps developers control the model behaviour more tightly by filtering model outputs.\n    * LLMs with retrieval can increase user trust by providing citation or automatically verifying facts.\n  * Performance goals vary widely -\n    * each Ai model has a fixed quality vel and cost but applications need to vary these parameters.\n",
        "\n",
        "[Full DB Genie documentation](llm-applications/db-genie.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Train Your Dragon (LLM)\n",
        "\n",
        "<figure><img src=\"../.gitbook/assets/image (5).png\" alt=\"\"><figcaption></figcaption></figure>\n\nOverview:\n\n* What is a LLM?\n* Transform artitecture\n* Overall process\n\n## What is a LLM?\n\n* Large language models\n* New era for NLP as earlier we had traditional methods which underperformed in tasks that demanded complex understanding and generation abilities.\n* ex— they were not able to write email from a list of keywords.\n* LLMs are trained on vast quantites of data, the sucess lies behind transformer architecture that underpins many LLMs and vast amount of data on which LLMs are trained on which allows them to capture wide variety of linguistic nuances, contexts and patterns that is challenging to encode manually.\n* These have billions of parameters which are adjustable weights in the network that are optimized during training to predict the next word in the sequece.\n* The transformer artitecture allows them to pay selective attention to different parts of input when making predictions making them especially adept at handling the nuances and complexities of human language.\n* LLMs can be categorised as an intersection between Deep learning and GenAI.\n* custom built LLMs those are tailored for specific tasks or domains can outperform general purpose LLMs such as ChatGPT.\n* THe pretrained model ChatGPT serve as a foundational resource that can be further refined through fine tuning, a process where the model is specifically trained on a narrower dataset that is more specific to a particular tasks.\n* LLMs user self-supervised learning where the model generated its own labels from the input data.\n",
        "\n",
        "[Full How to Train Your Dragon (LLM) documentation](llm-applications/how-to-train-your-dragon-llm.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieval Augmented Generation (RAG)\n",
        "\n",
        "## Overview\n\n* What is RAG?\n  *\n* Types of RAG\n  * Traditional RAG\n  * Graph RAG\n* Traditional RAG VS Graph RAG\n* Summary of RAG eco-system\n\n\\-----------------------------------------------------------------------------------------\n\n### What is RAG?\n\n<figure><img src=\"../.gitbook/assets/image (4).png\" alt=\"\"><figcaption></figcaption></figure>\n\n* LLM + external resources which were not included in their training\n  * i.e. Any LLM (gpt-4o, Gemini, llama) + internal document, service now ticket etc\n* RAG is GenAI design technique that enhances LLM with external knowledge, thus improving the LLMS with\n  * Proprietary knowledge - It includes proprietary info which wasn't initially used to train the LLMs such as emails, documentation etc. \n  * Up to date information - RAG application supply LLMs with info from updated data resources.\n  * Citing resources - RAG enables LLMs to cite specific resources thus allowing users to verify the factual accuracy of responses.\n",
        "\n",
        "[Full RAG documentation](llm-applications/rag.md)"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
